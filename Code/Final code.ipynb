{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57acafd8-e1e5-449e-b2cd-5a3a1cd84463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "import os\n",
    "# Set plotting style and directory\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"colorblind\")\n",
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b22e05-3442-40a7-a91c-b5fb0d463ccb",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabf5fa5-b1b5-48c6-a1bc-5c8d51207467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# PART 1: DATA LOADING AND PREPROCESSING\n",
    "\n",
    "#The analysis begins by loading and merging the article and model datasets using the DOI as the primary key. The preprocessing includes:\n",
    "  # - Data cleaning: Handling missing values, converting categorical fields, and addressing negative values in confidence intervals (which appear to be coding for missing data using -99)\n",
    "  # - New indicator variables: Creating flags for demographic groups based on the 'compare' column:\n",
    "    # - Black/African American comparisons\n",
    "    # - Hispanic/Latino comparisons\n",
    "    # - Asian/Pacific Islander comparisons\n",
    "    # - Indigenous/Native American comparisons\n",
    "    # - Missing data analysis: Visualizing patterns using missingno plots and determining whether imputation is appropriate\n",
    "#########################################################\n",
    "\n",
    "def load_data(article_path, model_path):\n",
    "    \"\"\"\n",
    "    Load article and model datasets\n",
    "    \"\"\"\n",
    "    print(\"Loading datasets...\")\n",
    "    article_df = pd.read_csv(\"article_dat.csv\")\n",
    "    model_df = pd.read_csv(\"model_dat.csv\")\n",
    "\n",
    "    print(f\"Article dataset shape: {article_df.shape}\")\n",
    "    print(f\"Model dataset shape: {model_df.shape}\")\n",
    "\n",
    "    return article_df, model_df\n",
    "\n",
    "def explore_data(article_df, model_df):\n",
    "    \"\"\"\n",
    "    Explore the raw datasets and report key insights\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Data Exploration ---\")\n",
    "\n",
    "    # Explore article data\n",
    "    print(\"\\nArticle data - column types:\")\n",
    "    print(article_df.dtypes.value_counts())\n",
    "\n",
    "    # Check health outcome-related columns\n",
    "    health_cols = [col for col in article_df.columns if 'health' in col or 'cancer' in col or\n",
    "                  'endo' in col or 'fibroid' in col or 'fert' in col or 'matmorb' in col]\n",
    "\n",
    "    print(f\"\\nHealth outcome columns: {health_cols}\")\n",
    "\n",
    "    health_counts = {}\n",
    "    for col in health_cols:\n",
    "        health_counts[col] = article_df[col].value_counts().get(1, 0)\n",
    "\n",
    "    print(\"Health outcome counts:\")\n",
    "    for col, count in sorted(health_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {col}: {count}\")\n",
    "\n",
    "    # Explore healthcare access and treatment columns\n",
    "    access_cols = ['access_to_care', 'treatment_received']\n",
    "\n",
    "    print(\"\\nHealthcare access and treatment columns:\")\n",
    "    for col in access_cols:\n",
    "        print(f\"  {col}: {article_df[col].value_counts().get(1, 0)} studies\")\n",
    "\n",
    "    # Explore model data\n",
    "    print(\"\\nModel data:\")\n",
    "    print(f\"  Number of unique effect size measures: {model_df['measure'].nunique()}\")\n",
    "    print(f\"  Most common effect size measures: {model_df['measure'].value_counts().head(5).to_dict()}\")\n",
    "\n",
    "    # Check effect size columns\n",
    "    effect_cols = ['point', 'lower', 'upper']\n",
    "    print(\"\\nEffect size columns - missing values:\")\n",
    "    for col in effect_cols:\n",
    "        missing = model_df[col].isnull().sum()\n",
    "        print(f\"  {col}: {missing} missing values ({missing/len(model_df)*100:.2f}%)\")\n",
    "\n",
    "    # Check negative values in confidence intervals (potential data coding issue)\n",
    "    for col in ['lower', 'upper']:\n",
    "        neg_values = (model_df[col] < 0).sum()\n",
    "        print(f\"  {col}: {neg_values} negative values ({neg_values/len(model_df)*100:.2f}%)\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def merge_datasets(article_df, model_df):\n",
    "    \"\"\"\n",
    "    Merge article and model datasets on DOI\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Merging Datasets ---\")\n",
    "\n",
    "    # Merge on DOI\n",
    "    df = pd.merge(model_df, article_df, on='doi', how='left')\n",
    "    print(f\"Merged dataset shape: {df.shape}\")\n",
    "\n",
    "    # Check if merge was successful\n",
    "    if len(df) == len(model_df):\n",
    "        print(\"All model records successfully matched with article data\")\n",
    "    else:\n",
    "        print(f\"Warning: {len(model_df) - len(df)} model records couldn't be matched\")\n",
    "\n",
    "    return df\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process\n",
    "\n",
    "\n",
    "def handle_compound_race(label):\n",
    "    \"\"\"\n",
    "    Standardizing race labels\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Standardizing race labels ---\")\n",
    "    if pd.isna(label):\n",
    "        return 'Unknown / Not Reported'\n",
    "\n",
    "    label = label.lower().strip()\n",
    "    label = re.sub(r'[;:,_]', '/', label)\n",
    "    label = re.sub(r'\\s*(and|or|/)\\s*', '/', label)\n",
    "    parts = [p.strip() for p in label.split('/') if p.strip()]\n",
    "\n",
    "    matched = set()\n",
    "    for part in parts:\n",
    "        if part in race_standardization:\n",
    "            matched.add(race_standardization[part])\n",
    "        else:\n",
    "            match, score, _ = process.extractOne(part, race_standardization.keys())\n",
    "            if score >= 90:\n",
    "                matched.add(race_standardization[match])\n",
    "\n",
    "    if not matched:\n",
    "        return 'Other / Multiracial'\n",
    "    elif len(matched) == 1:\n",
    "        return list(matched)[0]\n",
    "    else:\n",
    "        return 'Other / Multiracial'\n",
    "\n",
    "def standardize_race_labels(series, use_fuzzy=True, fuzzy_threshold=90):\n",
    "    def normalize(label):\n",
    "        if pd.isna(label):\n",
    "            return 'unknown'\n",
    "        return label.strip().lower()\n",
    "\n",
    "    def map_label(label):\n",
    "        if label in race_standardization:\n",
    "            return race_standardization[label]\n",
    "        if use_fuzzy:\n",
    "            match, score, _ = process.extractOne(label, race_standardization.keys())\n",
    "            if score >= fuzzy_threshold:\n",
    "                return race_standardization[match]\n",
    "        return handle_compound_race(label)\n",
    "\n",
    "    normalized_series = series.apply(normalize)\n",
    "    standardized_series = normalized_series.apply(map_label)\n",
    "\n",
    "    original_unmapped = series[~normalized_series.isin(race_standardization.keys())].unique()\n",
    "    if len(original_unmapped) > 0:\n",
    "        print(\"\\n⚠️ Unmapped race labels for review:\")\n",
    "        for label in original_unmapped:\n",
    "            print(f\"  - {label}\")\n",
    "\n",
    "    return standardized_series\n",
    "\n",
    "\n",
    "def analyze_missing_data(df):\n",
    "    \"\"\"\n",
    "    Analyze missing data patterns in the dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Missing Data Analysis ---\")\n",
    "\n",
    "    # Calculate missing data percentages\n",
    "    missing_data = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "    print(\"Columns with highest percentage of missing values:\")\n",
    "    print(missing_data[missing_data > 0].head(10))\n",
    "\n",
    "    # Check if imputation is needed\n",
    "    effect_cols = ['point', 'lower', 'upper']\n",
    "    missing_pct = df[effect_cols].isnull().mean() * 100\n",
    "    print(f\"\\nMissing data in effect size columns: {missing_pct.to_dict()}\")\n",
    "\n",
    "    if missing_pct.max() < 20:\n",
    "        print(\"Missing data percentage is below 20%, imputation can be applied\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"High percentage of missing data, analysis will proceed with complete cases only\")\n",
    "        return False\n",
    "\n",
    "def impute_missing_data(df, columns_to_impute):\n",
    "    \"\"\"\n",
    "    Impute missing values using KNN imputation\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Imputing Missing Data ---\")\n",
    "\n",
    "    # Create imputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Get subset of data for imputation\n",
    "    df_to_impute = df[columns_to_impute].copy()\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    df_to_impute_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(df_to_impute),\n",
    "        columns=df_to_impute.columns\n",
    "    )\n",
    "\n",
    "    # Perform imputation\n",
    "    print(f\"  Imputing {columns_to_impute} using KNN (k=5)\")\n",
    "    df_imputed_scaled = pd.DataFrame(\n",
    "        imputer.fit_transform(df_to_impute_scaled),\n",
    "        columns=df_to_impute.columns\n",
    "    )\n",
    "\n",
    "    # Reverse scaling\n",
    "    df_imputed = pd.DataFrame(\n",
    "        scaler.inverse_transform(df_imputed_scaled),\n",
    "        columns=df_to_impute.columns\n",
    "    )\n",
    "\n",
    "    # Create output dataframe\n",
    "    result_df = df.copy()\n",
    "    result_df[columns_to_impute] = df_imputed\n",
    "\n",
    "    # Report results\n",
    "    for col in columns_to_impute:\n",
    "        before = df[col].isnull().sum()\n",
    "        after = result_df[col].isnull().sum()\n",
    "        print(f\"  {col}: {before} missing values before, {after} missing values after imputation\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcda25-4c06-4cb3-820d-835eda291eb1",
   "metadata": {},
   "source": [
    "## Race standardization mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beaab814-76cf-4c68-a83e-098d3046b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercased standardized mapping\n",
    "race_standardization = {\n",
    "    'african american': 'Black or African American',\n",
    "    'african american or black': 'Black or African American',\n",
    "    'african american, non-hispanic': 'Black or African American',\n",
    "    'black': 'Black or African American',\n",
    "    'black or african american': 'Black or African American',\n",
    "    'black, non-hispanic': 'Black or African American',\n",
    "    'non african american': 'Black or African American',\n",
    "    'non-african american': 'Black or African American',\n",
    "    'non-hispanic black': 'Black or African American',\n",
    "\n",
    "    'caucasian': 'White',\n",
    "    'white': 'White',\n",
    "    'non hispanic white': 'White',\n",
    "    'non-hispanic white': 'White',\n",
    "    'non-latina white': 'White',\n",
    "    'white (non-hispanic)': 'White',\n",
    "    'white non-hispanic': 'White',\n",
    "    'white/caucasian': 'White',\n",
    "    'whites': 'White',\n",
    "    'u.s.-born, non-hispanic white;': 'White',\n",
    "    'non-hispanic, white': 'White',\n",
    "    'white donor / white recipient': 'White',\n",
    "    'european american': 'White',\n",
    "    'non hispanic whites': 'White',\n",
    "    'white, non-hispanic': 'White',\n",
    "\n",
    "    'hispanic': 'Hispanic or Latino',\n",
    "    'latina': 'Hispanic or Latino',\n",
    "    'latino': 'Hispanic or Latino',\n",
    "    'mexican/american': 'Hispanic or Latino',\n",
    "\n",
    "    'asian': 'Asian or Pacific Islander',\n",
    "    'asian, non-hispanic': 'Asian or Pacific Islander',\n",
    "    'asian american': 'Asian or Pacific Islander',\n",
    "    'pacific islander': 'Asian or Pacific Islander',\n",
    "\n",
    "    'american indian': 'American Indian or Alaska Native',\n",
    "    'american indian/alaska native': 'American Indian or Alaska Native',\n",
    "    'american indian/alaskan': 'American Indian or Alaska Native',\n",
    "    'american indian/alaskan native': 'American Indian or Alaska Native',\n",
    "    'native american': 'American Indian or Alaska Native',\n",
    "    'non-hispanic american indian or alaska native': 'American Indian or Alaska Native',\n",
    "\n",
    "    'minority': 'Other / Multiracial',\n",
    "    'nonwhite': 'Other / Multiracial',\n",
    "    'non-white': 'Other / Multiracial',\n",
    "    'urm (black, hispanic, native american/alaskan, asian/pacific islander, and other)': 'Other / Multiracial',\n",
    "    'other': 'Other / Multiracial',\n",
    "    'multiracial': 'Other / Multiracial',\n",
    "\n",
    "    'unknown': 'Unknown / Not Reported',\n",
    "    'not reported': 'Unknown / Not Reported'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e138c-91c5-4ceb-ac4a-11e807587864",
   "metadata": {},
   "source": [
    "## Main block to run preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5be7ba-8cbf-4e17-a3cf-d4decdcab28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Article dataset shape: (318, 65)\n",
      "Model dataset shape: (6804, 16)\n",
      "\n",
      "--- Data Exploration ---\n",
      "\n",
      "Article data - column types:\n",
      "float64    37\n",
      "object     24\n",
      "int64       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Health outcome columns: ['health_outcome', 'cancer_ovarian', 'cancer_uterine', 'cancer_cervical', 'cancer_vulvar', 'endo', 'fibroids', 'fert', 'matmorbmort']\n",
      "Health outcome counts:\n",
      "  health_outcome: 239\n",
      "  matmorbmort: 94\n",
      "  cancer_uterine: 69\n",
      "  cancer_ovarian: 50\n",
      "  fert: 31\n",
      "  cancer_cervical: 28\n",
      "  cancer_vulvar: 10\n",
      "  fibroids: 8\n",
      "  endo: 2\n",
      "\n",
      "Healthcare access and treatment columns:\n",
      "  access_to_care: 119 studies\n",
      "  treatment_received: 184 studies\n",
      "\n",
      "Model data:\n",
      "  Number of unique effect size measures: 83\n",
      "  Most common effect size measures: {'OR': 1975, 'Percent': 1370, 'RR': 1200, 'HR': 679, 'Incidence': 225}\n",
      "\n",
      "Effect size columns - missing values:\n",
      "  point: 36 missing values (0.53%)\n",
      "  lower: 235 missing values (3.45%)\n",
      "  upper: 237 missing values (3.48%)\n",
      "  lower: 2081 negative values (30.58%)\n",
      "  upper: 2043 negative values (30.03%)\n",
      "\n",
      "--- Merging Datasets ---\n",
      "Merged dataset shape: (6804, 80)\n",
      "All model records successfully matched with article data\n",
      "\n",
      "--- Missing Data Analysis ---\n",
      "Columns with highest percentage of missing values:\n",
      "eth7_ss    100.000000\n",
      "eth8_ss    100.000000\n",
      "eth7       100.000000\n",
      "eth8       100.000000\n",
      "eth4        99.221046\n",
      "eth4_ss     99.221046\n",
      "eth5        99.221046\n",
      "eth5_ss     99.221046\n",
      "eth6        99.221046\n",
      "eth6_ss     99.221046\n",
      "dtype: float64\n",
      "\n",
      "Missing data in effect size columns: {'point': 0.5291005291005291, 'lower': 3.453850676072898, 'upper': 3.4832451499118164}\n",
      "Missing data percentage is below 20%, imputation can be applied\n",
      "\n",
      "--- Imputing Missing Data ---\n",
      "  Imputing ['point', 'lower', 'upper'] using KNN (k=5)\n",
      "  point: 36 missing values before, 0 missing values after imputation\n",
      "  lower: 235 missing values before, 0 missing values after imputation\n",
      "  upper: 237 missing values before, 0 missing values after imputation\n",
      "\n",
      "=== ANALYSIS COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "# Set file paths\n",
    "article_path = 'article_dat.csv'\n",
    "model_path = 'model_dat.csv'\n",
    "\n",
    "\n",
    "article_df, model_df = load_data(article_path, model_path)\n",
    "explore_data(article_df, model_df)\n",
    "df = merge_datasets(article_df, model_df)\n",
    "should_impute = analyze_missing_data(df)\n",
    "\n",
    "    \n",
    "if should_impute:\n",
    "    effect_cols = ['point', 'lower', 'upper']\n",
    "    df = impute_missing_data(df, effect_cols)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24898a-2d59-43e3-8ad9-011413537b84",
   "metadata": {},
   "source": [
    "# Question 1: How are race and ethnicity categorized in medical research?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50a75f0-dfce-4596-be1c-d4edc80ec738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, ctx\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4569363-e2fc-47f4-91b7-204e0ee1040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_cols = [f\"race{i}\" for i in range(1, 9)]\n",
    "ss_cols = [f\"race{i}_ss\" for i in range(1, 9)]\n",
    "Q1_df=article_df.copy()\n",
    "Q1_df.loc[:, ss_cols] = Q1_df[ss_cols].replace(-99, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbc02894-0c38-4cf6-a2ea-c27f5780c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the desired columns\n",
    "columns_to_keep = [\n",
    "    \"pmid\", \"doi\", \"jabbrv\", \"journal\", \"year\", \"month\", \"day\", \n",
    "    \"title\", \"abstract\", \"keywords\", \"study_aim\", \"race1\", \"race1_ss\"\n",
    "]\n",
    "\n",
    "Q1_df = Q1_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a029e5ff-5c9f-4e39-b861-7184dd9fcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Standardizing race labels ---\n",
      "\n",
      "⚠️ Unmapped race labels for review:\n",
      "  - White - not Hispanic or Latino\n",
      "  - European Americans\n",
      "  - Black/African American\n",
      "  - Caucasians\n",
      "  - Non-Hispanic Asian\n",
      "  - White (or Caucasian)\n",
      "  - Unavailable\n",
      "  - Hispanic, Latina\n",
      "  - White-non-Hispanic\n"
     ]
    }
   ],
   "source": [
    "Q1_df['race_group'] = standardize_race_labels(Q1_df['race1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cd6b84b-638b-4b7e-9469-4facc49c5f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8021/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x176b6ee2930>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate article counts per race_group and year\n",
    "race_group_counts = Q1_df.groupby([\"year\", \"race_group\"]).size().reset_index(name=\"article_count\")\n",
    "\n",
    "min_year, max_year = int(df[\"year\"].min()), int(df[\"year\"].max())\n",
    "# Get a fixed list of all race groups\n",
    "all_race_groups = sorted(Q1_df[\"race_group\"].unique())\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id=\"race-group-line-chart\", style={\"width\": \"100%\", \"margin\": \"0 auto\", \"display\": \"block\"}),\n",
    "    \n",
    "    html.Div([\n",
    "        dcc.Slider(\n",
    "            id=\"year-slider\",\n",
    "            min=min_year,\n",
    "            max=max_year,\n",
    "            value=max_year,  # Default to most recent year\n",
    "            marks={year: str(year) for year in range(min_year, max_year + 1)},\n",
    "            step=1\n",
    "        ),\n",
    "        html.Button(\"Reset\", id=\"reset-button\", n_clicks=0),\n",
    "    ], id=\"slider-btn-div\", style={\"width\": \"50%\", \"margin\": \"0 auto\", \"textAlign\": \"center\"}),\n",
    "    \n",
    "    html.Div([\n",
    "        dcc.Graph(id=\"race-group-bar-chart\", style={\"width\": \"50%\", \"display\": \"inline-block\"}),\n",
    "        html.Img(id=\"word-cloud\", style={\"width\": \"50%\", \"display\": \"inline-block\"}),\n",
    "    ], style={\"display\": \"flex\", \"justify-content\": \"center\"}),\n",
    "    html.Div()\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [Output(\"race-group-bar-chart\", \"figure\"),\n",
    "     Output(\"race-group-line-chart\", \"figure\"),\n",
    "     Output(\"year-slider\", \"value\")],  # Allow reset button to reset slider value\n",
    "    [Input(\"year-slider\", \"value\"),\n",
    "     Input(\"reset-button\", \"n_clicks\")]\n",
    ")\n",
    "def update_charts(selected_year, reset_clicks):\n",
    "    triggered_id = ctx.triggered_id if ctx.triggered_id else \"year-slider\"\n",
    "    \n",
    "    if triggered_id == \"reset-button\" or not selected_year:\n",
    "        filtered_df = race_group_counts.groupby(\"race_group\")[\"article_count\"].sum().reset_index()\n",
    "        bar_title = \"Number of Articles by Race Group (All Years)\"\n",
    "        bar_chart = px.bar(filtered_df, x=\"race_group\", y=\"article_count\", title=bar_title)\n",
    "        selected_year = max_year  # Reset slider\n",
    "    else:\n",
    "        filtered_df = race_group_counts[race_group_counts[\"year\"] == selected_year]\n",
    "        full_data = pd.DataFrame({\"race_group\": all_race_groups})\n",
    "        filtered_df = full_data.merge(filtered_df, on=\"race_group\", how=\"left\").fillna(0)\n",
    "        filtered_df[\"article_count\"] = filtered_df[\"article_count\"].astype(int)\n",
    "        bar_title = f\"Number of Articles by Race Group ({selected_year})\"\n",
    "        bar_chart = px.bar(filtered_df, x=\"race_group\", y=\"article_count\", title=bar_title)\n",
    "    \n",
    "    line_chart = px.line(race_group_counts, x=\"year\", y=\"article_count\", color=\"race_group\", title=\"Articles Over Time by Race Group\")\n",
    "    line_chart.update_layout(legend=dict(font=dict(size=10)))  # Reduce legend font size\n",
    "    \n",
    "    return bar_chart, line_chart, selected_year\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"word-cloud\", \"src\"),\n",
    "    Input(\"race-group-bar-chart\", \"clickData\")\n",
    ")\n",
    "def update_word_cloud(click_data):\n",
    "    if click_data is None:\n",
    "        return None\n",
    "    \n",
    "    selected_race_group = click_data[\"points\"][0][\"x\"]\n",
    "    filtered_titles = Q1_df[Q1_df[\"race_group\"] == selected_race_group][\"title\"]\n",
    "    text = \" \".join(filtered_titles)\n",
    "    \n",
    "    wordcloud = WordCloud(width=400, height=300, background_color='white').generate(text)\n",
    "    img = BytesIO()\n",
    "    wordcloud.to_image().save(img, format=\"PNG\")\n",
    "    encoded_img = base64.b64encode(img.getvalue()).decode()\n",
    "    \n",
    "    return f\"data:image/png;base64,{encoded_img}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=8021,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720aefde-550a-4312-a4f0-a2097b432fbb",
   "metadata": {},
   "source": [
    "# Question 2: What health outcomes have been studied, and what disparities have been identified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bca313a9-eb44-4ccc-8976-99e4a7ac92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broad categories and associated keywords to classify outcomes\n",
    "category_keywords = {\n",
    "    'Maternal': ['maternal', 'cesarean', 'pregnancy-related mortality', 'hysterectomy', 'uterine', 'pregnancy', 'transfusion', 'ICU', 'perineal', 'postpartum'],\n",
    "    'Neonatal': ['neonatal', 'birthweight', 'NICU', 'apgar', 'infant', 'small for gestational age', 'preterm'],\n",
    "    'Fertility / ART': ['fertility', 'ivf', 'in vitro', 'oocyte', 'assisted reproductive', 'cryopreservation', 'gonadotropin', 'cycle', 'embryo'],\n",
    "    'Cancer': ['cancer', 'chemotherapy', 'oncology', 'tumor', 'nccn', 'radiotherapy', 'survival'],\n",
    "    'Mental Health': ['depression', 'stress', 'mental health'],\n",
    "    'COVID-19': ['covid', 'sars-cov-2', 'coronavirus'],\n",
    "    'Access & Experience': ['insurance', 'access', 'care', 'pain', 'disparity', 'recommendation letters'],\n",
    "    'Other': []  # default category for anything not matching above\n",
    "}\n",
    "\n",
    "# Function to categorize outcomes\n",
    "def categorize_outcome(outcome):\n",
    "    outcome_lower = str(outcome).lower()\n",
    "    for category, keywords in category_keywords.items():\n",
    "        if any(re.search(rf\"\\b{kw}\\b\", outcome_lower) for kw in keywords):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "# Combine and deduplicate all outcomes\n",
    "unique_outcomes = pd.Series(df['outcome'].dropna().tolist() + df['health_outcome'].dropna().tolist()).dropna()\n",
    "df['health_category'] = unique_outcomes.apply(categorize_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba7d0788-6a53-4d69-9d22-3c8ba4780eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating health outcome indicator variables\n",
      "  Creating race/ethnicity comparison indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheepie\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df = df.copy()\n",
    "# Create flags for health outcome-related columns\n",
    "print(\"  Creating health outcome indicator variables\")\n",
    "\n",
    "# 1. Main indicators\n",
    "for col in ['health_outcome', 'access_to_care', 'treatment_received']:\n",
    "    if col in clean_df.columns:\n",
    "        clean_df[f'has_{col}'] = clean_df[col].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# 2. Race/ethnicity indicators based on 'compare' column\n",
    "print(\"  Creating race/ethnicity comparison indicators\")\n",
    "\n",
    "clean_df['is_black_comparison'] = clean_df['compare'].str.contains(\n",
    "    'black|Black|African', case=False, na=False).astype(int)\n",
    "\n",
    "clean_df['is_hispanic_comparison'] = clean_df['compare'].str.contains(\n",
    "    'hispanic|latina|latino', case=False, na=False).astype(int)\n",
    "\n",
    "clean_df['is_asian_comparison'] = clean_df['compare'].str.contains(\n",
    "    'asian|pacific', case=False, na=False).astype(int)\n",
    "\n",
    "clean_df['is_indigenous_comparison'] = clean_df['compare'].str.contains(\n",
    "    'native|indian|indigenous|american indian|alaska', case=False, na=False).astype(int)\n",
    "\n",
    "# 3. Log-transform effect sizes for analysis\n",
    "clean_df['log_point'] = np.log(clean_df['point'].replace(0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a55ed8f-0920-4d3c-91fe-866dd8f54e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Analysis Datasets ---\n",
      "Health outcome dataset: 5212 records\n",
      "Access to care dataset: 3022 records\n",
      "Treatment received dataset: 3438 records\n",
      "Access and treatment dataset: 1894 records\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create datasets for health outcome analysis\n",
    "\"\"\"\n",
    "print(\"\\n--- Creating Analysis Datasets ---\")\n",
    "\n",
    "# Create health outcome dataset\n",
    "health_outcome_df = clean_df[clean_df['health_outcome'] == 1].copy()\n",
    "print(f\"Health outcome dataset: {health_outcome_df.shape[0]} records\")\n",
    "\n",
    "# Create dataset for access to care analysis\n",
    "access_df = clean_df[clean_df['access_to_care'] == 1].copy()\n",
    "print(f\"Access to care dataset: {access_df.shape[0]} records\")\n",
    "\n",
    "# Create dataset for treatment received analysis\n",
    "treatment_df = clean_df[clean_df['treatment_received'] == 1].copy()\n",
    "print(f\"Treatment received dataset: {treatment_df.shape[0]} records\")\n",
    "\n",
    "# Create dataset for both access and treatment\n",
    "access_treatment_df = clean_df[(clean_df['access_to_care'] == 1) &\n",
    "                             (clean_df['treatment_received'] == 1)].copy()\n",
    "print(f\"Access and treatment dataset: {access_treatment_df.shape[0]} records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae3a0b-847c-4c57-9945-1c16218c5485",
   "metadata": {},
   "source": [
    "## 2.1. Descriptive Analysis: What health outcomes have been studied?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1f34643-7ee0-4248-baf5-a29d7e3bd838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8022/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x176bd497800>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, html, dcc, Input, Output\n",
    "\n",
    "df['race1_clean'] = standardize_race_labels(df['race1'])\n",
    "app = Dash(__name__)\n",
    "\n",
    "# --- Preprocess data for dropdown and plots ---\n",
    "all_races = ['All'] + sorted(df['race1_clean'].dropna().unique().tolist())\n",
    "\n",
    "category_counts_all = df['health_category'].value_counts().reset_index()\n",
    "category_counts_all.columns = ['health_category', 'count']\n",
    "\n",
    "# --- Layout ---\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"Health Outcome Categories by Race\"),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Select Racial Group:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='race-selector',\n",
    "            options=[{'label': race, 'value': race} for race in all_races],\n",
    "            value='All',\n",
    "            clearable=False\n",
    "        )\n",
    "    ], style={'width': '30%', 'marginBottom': '20px'}),\n",
    "\n",
    "    dcc.Graph(id='category-bubble-chart'),\n",
    "\n",
    "    html.H4(\"Top 10 Health Outcomes in Selected Category\"),\n",
    "    dcc.Graph(id='top-outcomes-bar'),\n",
    "\n",
    "    html.H4(\"Heatmap of Health Category Prevalence by Race\"),\n",
    "    dcc.Graph(id='heatmap')\n",
    "])\n",
    "\n",
    "# --- Callbacks ---\n",
    "@app.callback(\n",
    "    Output('category-bubble-chart', 'figure'),\n",
    "    Input('race-selector', 'value')\n",
    ")\n",
    "def update_bubble_chart(selected_race):\n",
    "    if selected_race == 'All':\n",
    "        data = df\n",
    "    else:\n",
    "        data = df[df['race1_clean'] == selected_race]\n",
    "\n",
    "    category_counts = data[data['health_category'] != 'Other']['health_category'].value_counts().reset_index()\n",
    "    category_counts.columns = ['health_category', 'count']\n",
    "\n",
    "    fig = px.scatter(\n",
    "        category_counts,\n",
    "        x='health_category', y=[1]*len(category_counts),\n",
    "        size='count', color='count', text='health_category',\n",
    "        size_max=100, height=400, color_continuous_scale='Viridis_r'\n",
    "    )\n",
    "    fig.update_traces(textposition='middle center')\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        xaxis_title='', yaxis_title='',\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        title=\"Prevalence of Health Outcome Categories\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('top-outcomes-bar', 'figure'),\n",
    "    Input('race-selector', 'value')\n",
    ")\n",
    "def update_outcomes_bar(selected_race):\n",
    "    if selected_race == 'All':\n",
    "        data = df\n",
    "    else:\n",
    "        data = df[df['race1_clean'] == selected_race]\n",
    "\n",
    "    outcome_counts = data['outcome'].value_counts().head(10).reset_index()\n",
    "    outcome_counts.columns = ['outcome', 'count']\n",
    "    outcome_counts = outcome_counts.sort_values('count', ascending=True)\n",
    "\n",
    "    fig = px.bar(\n",
    "        outcome_counts,\n",
    "        x='count', y='outcome', orientation='h',\n",
    "        color='count', color_continuous_scale='Viridis_r'\n",
    "    )\n",
    "    fig.update_layout(title=\"Top 10 Health Outcomes\", yaxis_title=\"Outcome\", xaxis_title=\"Count\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('heatmap', 'figure'),\n",
    "    Input('race-selector', 'value')\n",
    ")\n",
    "def update_heatmap(selected_race):\n",
    "    data = df[df['health_category'] != 'Other']\n",
    "\n",
    "    if selected_race != 'All':\n",
    "        data = data[data['race1_clean'] == selected_race]\n",
    "\n",
    "    heatmap_data = data.groupby(['race1_clean', 'health_category']).size().reset_index(name='count')\n",
    "    pivot = heatmap_data.pivot(index='race1_clean', columns='health_category', values='count').fillna(0)\n",
    "\n",
    "    fig = px.imshow(\n",
    "        pivot,\n",
    "        text_auto=True,\n",
    "        labels=dict(x=\"Health Category\", y=\"Race\", color=\"Count\"),\n",
    "        title=\"Heatmap of Health Category Prevalence by Race\",\n",
    "        aspect=\"auto\",\n",
    "        height=500\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Run App ---\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=8022, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee8c277-321b-4b08-90e5-09878982d46c",
   "metadata": {},
   "source": [
    "## 2.2 Compare effect sizes and visualize disparities between different race groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7068ba74-7e0a-4366-a929-aef172405b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheepie\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8023/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x176b2203080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define effect size measures\n",
    "common_measures = ['OR', 'RR', 'HR']\n",
    "effect_df = health_outcome_df[health_outcome_df['measure'].isin(common_measures)].copy()\n",
    "\n",
    "# Log-transform effect sizes\n",
    "effect_df['log_point'] = np.log(effect_df['point'].replace(0, np.nan))\n",
    "\n",
    "# Define demographic groups\n",
    "demo_groups = {\n",
    "    'is_black_comparison': 'Black/African American',\n",
    "    'is_hispanic_comparison': 'Hispanic/Latino',\n",
    "    'is_asian_comparison': 'Asian/Pacific Islander',\n",
    "    'is_indigenous_comparison': 'Indigenous/Native'\n",
    "}\n",
    "\n",
    "# Dropdown options\n",
    "race_options = [{\"label\": name, \"value\": key} for key, name in demo_groups.items()]\n",
    "\n",
    "# Identify top outcomes\n",
    "top_outcomes = effect_df['outcome'].value_counts().head(5).index.tolist()\n",
    "\n",
    "# App layout with vertical stacking\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"Effect Sizes by Demographic Group\", style={\"textAlign\": \"center\"}),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id=\"group-selector\",\n",
    "        options=race_options,\n",
    "        value=\"is_black_comparison\",\n",
    "        style={\"width\": \"50%\", \"margin\": \"0 auto 30px auto\"}\n",
    "    ),\n",
    "\n",
    "    html.Div([\n",
    "        html.H4(\"Violin Plot: Log Effect Size Distribution\", style={\"textAlign\": \"center\"}),\n",
    "        html.Img(id=\"violin-plot\", style={\"width\": \"80%\", \"margin\": \"auto\", \"display\": \"block\", \"marginBottom\": \"50px\"}),\n",
    "    ]),\n",
    "\n",
    "    html.Div([\n",
    "        html.H4(\"Forest Plot: Top Health Outcomes\", style={\"textAlign\": \"center\"}),\n",
    "        html.Img(id=\"forest-plot\", style={\"width\": \"80%\", \"margin\": \"auto\", \"display\": \"block\"})\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Callback to update both plots\n",
    "@app.callback(\n",
    "    [Output(\"violin-plot\", \"src\"),\n",
    "     Output(\"forest-plot\", \"src\")],\n",
    "    Input(\"group-selector\", \"value\")\n",
    ")\n",
    "def update_plots(group_key):\n",
    "    group_name = demo_groups[group_key]\n",
    "    group_data = effect_df[effect_df[group_key] == 1].copy()\n",
    "\n",
    "    #### --- VIOLIN PLOT --- ####\n",
    "    violin_src = None\n",
    "    if not group_data.empty:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.violinplot(x='measure', y='log_point', data=group_data)\n",
    "        ax.axhline(y=0, color='r', linestyle='--')\n",
    "        ax.set_title(f'{group_name}')\n",
    "        ax.set_ylabel('Log Effect Size')\n",
    "        ax.set_xlabel('Effect Measure')\n",
    "        for i, measure in enumerate(group_data['measure'].unique()):\n",
    "            count = len(group_data[group_data['measure'] == measure])\n",
    "            ax.text(i, ax.get_ylim()[1]*0.9, f'n={count}', ha='center')\n",
    "        buf_v = BytesIO()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(buf_v, format=\"png\")\n",
    "        plt.close()\n",
    "        violin_src = f\"data:image/png;base64,{base64.b64encode(buf_v.getvalue()).decode()}\"\n",
    "\n",
    "    #### --- FOREST PLOT --- ####\n",
    "    forest_src = None\n",
    "    forest_data = group_data[\n",
    "        group_data['outcome'].isin(top_outcomes) &\n",
    "        (~group_data['point'].isnull()) &\n",
    "        (~group_data['lower'].isnull()) &\n",
    "        (~group_data['upper'].isnull())\n",
    "    ]\n",
    "\n",
    "    forest_stats = []\n",
    "    for outcome in top_outcomes:\n",
    "        for measure in ['OR', 'RR']:\n",
    "            subset = forest_data[\n",
    "                (forest_data['outcome'] == outcome) &\n",
    "                (forest_data['measure'] == measure)\n",
    "            ]\n",
    "            if len(subset) >= 3:\n",
    "                forest_stats.append({\n",
    "                    \"Outcome\": outcome,\n",
    "                    \"Measure\": measure,\n",
    "                    \"Count\": len(subset),\n",
    "                    \"Point\": subset[\"point\"].median(),\n",
    "                    \"Lower\": subset[\"lower\"].median(),\n",
    "                    \"Upper\": subset[\"upper\"].median()\n",
    "                })\n",
    "\n",
    "    if forest_stats:\n",
    "        forest_df = pd.DataFrame(forest_stats).sort_values(['Outcome', 'Measure', 'Point'])\n",
    "        plt.figure(figsize=(11, len(forest_df) + 3))\n",
    "        y_pos = np.arange(len(forest_df))\n",
    "        plt.errorbar(\n",
    "            x=forest_df['Point'],\n",
    "            y=y_pos,\n",
    "            xerr=[forest_df['Point'] - forest_df['Lower'], forest_df['Upper'] - forest_df['Point']],\n",
    "            fmt='o', capsize=5\n",
    "        )\n",
    "        plt.yticks(y_pos, forest_df['Outcome'] + ' (' + forest_df['Measure'] + ', n=' + forest_df['Count'].astype(str) + ')')\n",
    "        plt.axvline(x=1, color='r', linestyle='--')\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Effect Size (OR/RR)')\n",
    "        plt.title(f'{group_name}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        buf_f = BytesIO()\n",
    "        plt.savefig(buf_f, format=\"png\")\n",
    "        plt.close()\n",
    "        forest_src = f\"data:image/png;base64,{base64.b64encode(buf_f.getvalue()).decode()}\"\n",
    "\n",
    "    return violin_src, forest_src\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, port=8023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fbf861-ef09-403b-a890-f0a4eda84360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
